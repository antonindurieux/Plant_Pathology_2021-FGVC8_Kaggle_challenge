{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["This Notebook presents a part of my code for the Plant Pathology 2021 - FGVC8 Kaggle challenge. \n","\n","It shows the code for the inference on the test data.  \n","\n","This notebook version doesn't exactly correspond to the code I submitted for the competition, as the requirements specified that the internet access had to be disabled. Thus it wasn't possible to install python packages and to connect to the Google Cloud Storage bucket of the test data.  \n","One can get around that :\n","- By getting the data from the local file system instead of the GSC bucket, at the cost of not being able to use the TPUs in a straightforward way (but then GPUs could do the job). \n","- It was possible not to install the extra packages by loading the models with the `tf.keras.models.load_model` function. In this case, some (quick & dirty) adaptations had to be made to get it to work properly.  \n","\n","For the sake of clarity and simplicity, this notebook will avoid those particular technical complications, by showing an implementation using an internet access and TPUs.\n","\n","Another thing to consider is that **only 3 images from the test set were accessible**, the remaing ~2700 images being hidden and only accessible during submission runtime. Thus the following code is applied on only 3 examples. The submissions took much longer time and processing power due to this difference.\n","\n","Other parts of the code can be found here :\n","- [**ResNet50 model training**](https://github.com/antonindurieux/Plant_Pathology_2021-FGVC8_Kaggle_challenge/blob/master/1_plant-pathology-2021-fgvc8-resnet50-training.ipynb) ;\n","- [**EfficientNetB7 model training**]() ;\n","- [**Vision Transformer model training**]().\n","\n","An article about this project can be found on my website [**here**](https://antonindurieux.github.io/portfolio/1_Kaggle_Plant_Pathology_2021_competition/)."],"metadata":{}},{"cell_type":"markdown","source":["## 1. Import and configuration"],"metadata":{}},{"cell_type":"markdown","source":["As Vision Transformers are not yet implemented in Keras and TensorFlow at the time of this writing, I used this helpful [python package](https://pypi.org/project/vit-keras/) which seemed to work well enough.  \n","I used [this implementation](https://github.com/qubvel/efficientnet) for the EfficientNet so I could properly load the Noisy Student weights."],"metadata":{}},{"cell_type":"code","source":["!pip install --quiet vit-keras\n","!pip install --quiet efficientnet"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:36:49.388281Z","iopub.execute_input":"2021-06-05T09:36:49.390641Z","iopub.status.idle":"2021-06-05T09:37:03.205918Z","shell.execute_reply.started":"2021-06-05T09:36:49.390538Z","shell.execute_reply":"2021-06-05T09:37:03.204314Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Imports\n","import os\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from tqdm import tqdm\n","from matplotlib import pyplot as plt\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import tensorflow as tf\n","from tensorflow.keras.layers import Flatten, Dense\n","import tensorflow_addons as tfa\n","from efficientnet.tfkeras import EfficientNetB7\n","from vit_keras import vit\n","\n","sns.set()"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-05T09:37:03.208988Z","iopub.execute_input":"2021-06-05T09:37:03.209451Z","iopub.status.idle":"2021-06-05T09:37:03.223601Z","shell.execute_reply.started":"2021-06-05T09:37:03.209393Z","shell.execute_reply":"2021-06-05T09:37:03.222337Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["We configure the TPUs, the batch size and the image resolutions corresponding to the different models :"],"metadata":{}},{"cell_type":"code","source":["# TPU configuration\n","try:\n","    # TPU detection\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n","    # Connection to TPU\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    # Initialization of the TPU devices\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    # Create a state & distribution policy on the TPU devices\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","\n","except ValueError:\n","    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n","    strategy = tf.distribute.MirroredStrategy()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:03.227945Z","iopub.execute_input":"2021-06-05T09:37:03.228542Z","iopub.status.idle":"2021-06-05T09:37:08.449126Z","shell.execute_reply.started":"2021-06-05T09:37:03.228493Z","shell.execute_reply":"2021-06-05T09:37:08.447825Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Running on TPU  ['10.0.0.2:8470']\n","output_type":"stream"}]},{"cell_type":"code","source":["# Small batch size due to memory constraints during submission\n","BATCH_SIZE = 32"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:08.451211Z","iopub.execute_input":"2021-06-05T09:37:08.451650Z","iopub.status.idle":"2021-06-05T09:37:08.456954Z","shell.execute_reply.started":"2021-06-05T09:37:08.451603Z","shell.execute_reply":"2021-06-05T09:37:08.455969Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Image resolution for the different models\n","IMG_RES_RESNET = 400\n","IMG_RES_EFFNET = 600\n","IMG_RES_VIT = 608"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:08.458413Z","iopub.execute_input":"2021-06-05T09:37:08.458695Z","iopub.status.idle":"2021-06-05T09:37:08.472448Z","shell.execute_reply.started":"2021-06-05T09:37:08.458667Z","shell.execute_reply":"2021-06-05T09:37:08.471391Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["## 2. Data imports and datasets generation\n","\n","First, we will get the list of labels corresponding to the different pathologies (in the same order as for the training process so as not to mix everything up).  \n","Then we will get the test files list.  \n","Finally, we will generate a test dataset for each model.  \n","\n","Using [Test Time Augmentation (TTA)](https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d) significantly improved the results. The TTA steps were the same as for the training process. They are implemented in the dataset creation pipeline."],"metadata":{}},{"cell_type":"code","source":["# Get the pathology labels \n","train_label_csv = \"../input/plant-pathology-2021-fgvc8/train.csv\"\n","train_label_df = pd.read_csv(train_label_csv)\n","train_label_df['labels_list'] = train_label_df.labels.apply(lambda x: x.split(' '))\n","\n","mlb = MultiLabelBinarizer()\n","mlb.fit(train_label_df.labels_list)\n","pathologies = mlb.classes_"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:08.473866Z","iopub.execute_input":"2021-06-05T09:37:08.474171Z","iopub.status.idle":"2021-06-05T09:37:08.534101Z","shell.execute_reply.started":"2021-06-05T09:37:08.474141Z","shell.execute_reply":"2021-06-05T09:37:08.532796Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Get GCS bucket path\n","gcs_ds_path = KaggleDatasets().get_gcs_path(\"plant-pathology-2021-fgvc8\")\n","\n","# Get the images paths\n","test_images_path = gcs_ds_path + \"/test_images/\"\n","test_files_ls = tf.io.gfile.glob(test_images_path + '*.jpg')"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:08.535633Z","iopub.execute_input":"2021-06-05T09:37:08.535975Z","iopub.status.idle":"2021-06-05T09:37:08.966385Z","shell.execute_reply.started":"2021-06-05T09:37:08.535939Z","shell.execute_reply":"2021-06-05T09:37:08.965244Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def crop_center(image):\n","    \"\"\"\n","    Crop an image to its central square\n","    \"\"\"\n","    h, w = tf.shape(image)[-3], tf.shape(image)[-2]\n","    if h > w:\n","        cropped_image = tf.image.crop_to_bounding_box(image, (h - w) // 2, 0, w, w)\n","    else:\n","        cropped_image = tf.image.crop_to_bounding_box(image, 0, (w - h) // 2, h, h)\n","    return cropped_image\n","\n","def test_time_augmentation(image, img_crop_resolution):\n","    \"\"\"\n","    Apply Test Time Augmentation to images\n","    \"\"\"\n","    image = tf.image.random_brightness(image, 0.3)\n","    image = tf.image.random_contrast(image, 1, 3)\n","    image = tf.image.random_saturation(image, 1, 1.3) \n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_crop(image, [img_crop_resolution, img_crop_resolution, 3])\n","    return image\n","\n","def process_test_img(filepath, img_resize_resolution):\n","    \"\"\"\n","    Read an image from its filepath, crop it to its central square and resize it\n","    \"\"\"\n","    image = tf.io.read_file(filepath)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.convert_image_dtype(image, tf.float32) \n","    image = crop_center(image)\n","    image = tf.image.resize(image, [img_resize_resolution, img_resize_resolution])\n","    return image\n","\n","def get_test_dataset(filenames, img_resize_resolution, tta, img_crop_resolution=None):\n","    \"\"\"\n","    Create the test dataset\n","    \"\"\"\n","    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n","    dataset = dataset.map(lambda x: process_test_img(x, img_resize_resolution))\n","    if tta:\n","        dataset = dataset.map(lambda x: test_time_augmentation(x, img_crop_resolution))\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:08.968179Z","iopub.execute_input":"2021-06-05T09:37:08.968506Z","iopub.status.idle":"2021-06-05T09:37:08.983885Z","shell.execute_reply.started":"2021-06-05T09:37:08.968473Z","shell.execute_reply":"2021-06-05T09:37:08.982673Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["ds_test_resnet = get_test_dataset(test_files_ls, img_resize_resolution=450, tta=True, img_crop_resolution=IMG_RES_RESNET)\n","ds_test_effnet = get_test_dataset(test_files_ls, img_resize_resolution=700, tta=True, img_crop_resolution=IMG_RES_EFFNET)\n","# No TTA for the Vision Transformer model\n","ds_test_vit = get_test_dataset(test_files_ls, img_resize_resolution=IMG_RES_VIT, tta=False)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:08.987586Z","iopub.execute_input":"2021-06-05T09:37:08.987947Z","iopub.status.idle":"2021-06-05T09:37:09.858555Z","shell.execute_reply.started":"2021-06-05T09:37:08.987914Z","shell.execute_reply":"2021-06-05T09:37:09.857612Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["## 3. Inference\n","\n","Now we will load the 3 different models, and proceed to the inference process.  \n","\n","Due to time limitations at submission runtime, I was limited in the number of TTA steps I could apply. The best compromise between runtime duration and performance was obtained with :\n","- ResNet50 : 2 TTA steps\n","- EfficentNetB7 : 2 TTA steps\n","- Vision Transformer : no TTA.  \n","\n","The TTA results matrices will be averaged for each model.\n","\n","This process took ~2 hours on the full test set at runtime.\n","\n","### 3.1 ResNet50"],"metadata":{}},{"cell_type":"code","source":["resnet_model_path = \"../input/resnet-tpu-v2/resnet_tpu_v2.h5\""],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:09.860454Z","iopub.execute_input":"2021-06-05T09:37:09.860857Z","iopub.status.idle":"2021-06-05T09:37:09.865643Z","shell.execute_reply.started":"2021-06-05T09:37:09.860820Z","shell.execute_reply":"2021-06-05T09:37:09.864318Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["with strategy.scope():\n","    resnet_model = tf.keras.models.load_model(resnet_model_path, compile=False)\n","    resnet_model.compile()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:09.867140Z","iopub.execute_input":"2021-06-05T09:37:09.867450Z","iopub.status.idle":"2021-06-05T09:37:25.266646Z","shell.execute_reply.started":"2021-06-05T09:37:09.867417Z","shell.execute_reply":"2021-06-05T09:37:25.265609Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["resnet_tta_steps = 2\n","predictions = []\n","\n","for i in tqdm(range(resnet_tta_steps)):\n","    resnet_preds = resnet_model.predict(ds_test_resnet, batch_size=BATCH_SIZE, verbose=1)\n","    predictions.append(resnet_preds)\n","\n","resnet_preds_tta = np.mean(predictions, axis=0)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:25.268177Z","iopub.execute_input":"2021-06-05T09:37:25.268491Z","iopub.status.idle":"2021-06-05T09:37:44.324575Z","shell.execute_reply.started":"2021-06-05T09:37:25.268462Z","shell.execute_reply":"2021-06-05T09:37:44.323358Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"  0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 17s 17s/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 1/2 [00:17<00:17, 17.51s/it]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 1s 1s/step\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [00:19<00:00,  9.52s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### 3.2 EfficientNetB7"],"metadata":{}},{"cell_type":"code","source":["effnet_model_path = \"../input/effnetb7/effnetB7.h5\""],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:44.326009Z","iopub.execute_input":"2021-06-05T09:37:44.326323Z","iopub.status.idle":"2021-06-05T09:37:44.330751Z","shell.execute_reply.started":"2021-06-05T09:37:44.326291Z","shell.execute_reply":"2021-06-05T09:37:44.329484Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["with strategy.scope():\n","    effnet_model = tf.keras.models.load_model(effnet_model_path, compile=False)\n","    effnet_model.compile()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:37:44.332109Z","iopub.execute_input":"2021-06-05T09:37:44.332469Z","iopub.status.idle":"2021-06-05T09:38:30.611452Z","shell.execute_reply.started":"2021-06-05T09:37:44.332434Z","shell.execute_reply":"2021-06-05T09:38:30.610239Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["effnet_tta_steps = 2\n","predictions = []\n","\n","for i in tqdm(range(effnet_tta_steps)):\n","    effnet_preds = effnet_model.predict(ds_test_effnet, batch_size=BATCH_SIZE, verbose=1)\n","    predictions.append(effnet_preds)\n","\n","effnet_preds_tta = np.mean(predictions, axis=0)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:38:30.612984Z","iopub.execute_input":"2021-06-05T09:38:30.613308Z","iopub.status.idle":"2021-06-05T09:39:05.936733Z","shell.execute_reply.started":"2021-06-05T09:38:30.613277Z","shell.execute_reply":"2021-06-05T09:39:05.935741Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"  0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 34s 34s/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 1/2 [00:33<00:33, 33.68s/it]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [00:35<00:00, 17.66s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":["### 3.3 Vision Transformer"],"metadata":{}},{"cell_type":"code","source":["vit_model_path = \"../input/vit-model-600x600/vit_model_600x600.h5\""],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:05.938247Z","iopub.execute_input":"2021-06-05T09:39:05.938564Z","iopub.status.idle":"2021-06-05T09:39:05.942487Z","shell.execute_reply.started":"2021-06-05T09:39:05.938530Z","shell.execute_reply":"2021-06-05T09:39:05.941696Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# The Vision Transformer model has to be built again so that the weights loading works properly\n","n_labels = len(pathologies)\n","inputs = tf.keras.Input(shape=(IMG_RES_VIT, IMG_RES_VIT) + (3,))\n","\n","with strategy.scope():\n","    vit_model = vit.vit_b16(\n","        image_size = IMG_RES_VIT,\n","        activation = 'sigmoid',\n","        pretrained = False,\n","        include_top = False,\n","        pretrained_top = False,\n","        classes = len(pathologies))\n","    \n","    x = vit_model(inputs, training=True)\n","    x = Flatten()(x)\n","    outputs = Dense(n_labels, activation = 'sigmoid')(x)\n","\n","    vit_model = tf.keras.Model(inputs, outputs)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:05.943884Z","iopub.execute_input":"2021-06-05T09:39:05.944408Z","iopub.status.idle":"2021-06-05T09:39:12.851769Z","shell.execute_reply.started":"2021-06-05T09:39:05.944374Z","shell.execute_reply":"2021-06-05T09:39:12.850503Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["vit_model.load_weights(vit_model_path)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:12.853168Z","iopub.execute_input":"2021-06-05T09:39:12.853488Z","iopub.status.idle":"2021-06-05T09:39:22.243618Z","shell.execute_reply.started":"2021-06-05T09:39:12.853456Z","shell.execute_reply":"2021-06-05T09:39:22.242288Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["vit_preds = vit_model.predict(ds_test_vit, batch_size=BATCH_SIZE, verbose=1)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:22.245281Z","iopub.execute_input":"2021-06-05T09:39:22.245779Z","iopub.status.idle":"2021-06-05T09:39:35.830183Z","shell.execute_reply.started":"2021-06-05T09:39:22.245701Z","shell.execute_reply":"2021-06-05T09:39:35.828633Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 14s 14s/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":["## 4. Outputs processing"],"metadata":{}},{"cell_type":"markdown","source":["Now we will average the 3 prediction probability matrices.  \n","Subsequent processing on the resulting matrix will be :\n","- To apply thresholds to get labels from probabilities. I just applied a threshold of 0.5 for each label in my final solution.\n","- If all the probabilites are below the tresholds for a particular image, we will select the maximum probability label.  \n","\n","Then a submission csv file can be generated and we are done !"],"metadata":{}},{"cell_type":"code","source":["# Averaging the predictions of the 3 models\n","mean_predictions = np.mean([effnet_preds_tta, resnet_preds_tta, vit_preds], axis=0)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:35.832112Z","iopub.execute_input":"2021-06-05T09:39:35.832603Z","iopub.status.idle":"2021-06-05T09:39:35.840143Z","shell.execute_reply.started":"2021-06-05T09:39:35.832547Z","shell.execute_reply":"2021-06-05T09:39:35.837940Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def format_predictions(preds, files, thresholds, fill_no_label=False, labels=pathologies, oh_labels=True):\n","    \"\"\"\n","    Format predictions to get a DataFrame from the prediction matrix\n","\n","    Args:\n","        preds (float32 numpy array): predictions matrix (N_IMAGES, N_LABELS)\n","        files (list): list of image files\n","        thresholds (list): list of prediction thresholds associated with each labels \n","        fill_no_label (boolean): wether or not to fill empty predictions with argmax\n","        labels (list): list of labels names\n","        oh_labels (boolean): wether or not to get booleans associated with labels in the output DataFrame\n","\n","    Returns:\n","        predictions_df (DataFrame): predictions DataFrame\n","    \"\"\"\n","\n","    preds_copy = preds.copy()\n","\n","    # Handling no label cases\n","    if fill_no_label:\n","        for i in range(preds_copy.shape[0]):\n","            if np.all(preds_copy[i, :] < thresholds):\n","                preds_copy[i, np.argmax(preds_copy[i, :])] = 1\n","\n","    # Apply thresholds to get boolean values\n","    for j in range(preds_copy.shape[1]):\n","        preds_copy[:, j] = np.where(preds_copy[:, j] < thresholds[j], 0, 1)\n","\n","    # Reverse MultiLabelBinarizer\n","    mlb_predictions = mlb.inverse_transform(preds_copy)\n","    mlb_predictions = [' '.join(x) for x in mlb_predictions]\n","\n","    # Create the output DataFrame\n","    predictions_series = pd.Series(mlb_predictions, name=\"labels\")\n","    oh_predictions_df = pd.DataFrame(data=preds_copy, columns=labels)\n","    file_names = [x.split('/')[-1] for x in files]\n","    file_names_series = pd.Series(file_names, name=\"file_name\")\n","    predictions_df = pd.concat([file_names_series, predictions_series], axis=1)\n","\n","    # Get one-hot-labels in the output DataFrame\n","    if oh_labels:\n","        predictions_df = pd.concat([predictions_df, oh_predictions_df], axis=1)\n","\n","    return predictions_df"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:35.842316Z","iopub.execute_input":"2021-06-05T09:39:35.843211Z","iopub.status.idle":"2021-06-05T09:39:35.864452Z","shell.execute_reply.started":"2021-06-05T09:39:35.843147Z","shell.execute_reply":"2021-06-05T09:39:35.863059Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["test_img_names = [file_path.split('/')[-1] for file_path in test_files_ls]\n","\n","# Thresholds will be 0.5 for each label\n","thresholds = [0.5] * n_labels\n","\n","# Final predictions DataFrame\n","predictions_df = format_predictions(mean_predictions, test_img_names, thresholds, fill_no_label=True, labels=pathologies, oh_labels=False)\n","predictions_df"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:35.865969Z","iopub.execute_input":"2021-06-05T09:39:35.866277Z","iopub.status.idle":"2021-06-05T09:39:35.887995Z","shell.execute_reply.started":"2021-06-05T09:39:35.866248Z","shell.execute_reply":"2021-06-05T09:39:35.887086Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"              file_name              labels\n0  85f8cb619c66b863.jpg                scab\n1  ad8770db05586b59.jpg  frog_eye_leaf_spot\n2  c7b03e718489f3ca.jpg  frog_eye_leaf_spot","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>85f8cb619c66b863.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ad8770db05586b59.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c7b03e718489f3ca.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["predictions_df.to_csv('submission.csv', index=False)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:39:35.890719Z","iopub.execute_input":"2021-06-05T09:39:35.891123Z","iopub.status.idle":"2021-06-05T09:39:35.907571Z","shell.execute_reply.started":"2021-06-05T09:39:35.891083Z","shell.execute_reply":"2021-06-05T09:39:35.906267Z"},"trusted":true},"execution_count":46,"outputs":[]}]}